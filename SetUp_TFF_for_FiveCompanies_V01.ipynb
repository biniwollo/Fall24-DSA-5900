{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNLmzkLakHaXu25KiIIZywD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biniwollo/Fall24-DSA-5900/blob/main/SetUp_TFF_for_FiveCompanies_V01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-by-Step Guide to Setting Up Federated Learning with TensorFlow Federated:\n",
        "1. Install TensorFlow Federated\n",
        "\n",
        "You first need to install the tensorflow-federated library.\n",
        "\n",
        "In Google Colab, or your local Python environment, run:"
      ],
      "metadata": {
        "id": "pVKG_jkpKNHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install TensorFlow Federated"
      ],
      "metadata": {
        "id": "RrsKY-CShBgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFc454D2bT1J",
        "outputId": "5fe719b1-65bf-414e-c2f4-68e5755b0049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install tensorflow federated\n",
        "!pip install tensorflow-federated\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HSABqPDUgzL7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Import TensorFlow Federated"
      ],
      "metadata": {
        "id": "DvIJCacmh1E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_federated as tff\n",
        "\n",
        "# Verify TensorFlow Federated version\n",
        "print(f\"TensorFlow Federated Version: {tff.__version__}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWBmERLTUexu",
        "outputId": "652a2ffa-238f-4b35-fa77-61065ca54eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Federated Version: 0.87.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve Stock Data from Yahoo Finance"
      ],
      "metadata": {
        "id": "VrrFwLHikRLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "id": "ySfLiO05kd88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6e3c1e44-d0a9-47eb-d7f7-a0a0f36563d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.40)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.25.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.2.2)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.4)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the companies and their ticker symbols\n",
        "companies = {\n",
        "    'John Deere': 'DE',\n",
        "    'Archer-Daniels-Midland': 'ADM',\n",
        "    'Bunge Ltd': 'BG',\n",
        "    'The Mosaic Company': 'MOS',\n",
        "    'Corteva': 'CTVA'\n",
        "}\n",
        "\n",
        "# Set up directory in the default Colab environment\n",
        "base_dir = '/content/FinancialData'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Loop through each company and download the stock data\n",
        "for company, ticker in companies.items():\n",
        "    print(f\"Downloading data for {company} ({ticker})...\")\n",
        "    stock_data = yf.download(ticker, start='2019-09-16', end='2024-09-13')\n",
        "    file_path = os.path.join(base_dir, f\"{ticker}_stock_data.csv\")\n",
        "    stock_data.to_csv(file_path)\n",
        "    print(f\"Data for {company} ({ticker}) saved successfully at {file_path}\")\n",
        "\n",
        "# Combine all data into a single CSV (optional)\n",
        "combined_file_path = os.path.join(base_dir, \"combined_stock_data.csv\")\n",
        "combined_stock_data = pd.concat([pd.read_csv(os.path.join(base_dir, f\"{ticker}_stock_data.csv\")) for ticker in companies.values()])\n",
        "combined_stock_data.to_csv(combined_file_path, index=False)\n",
        "print(f\"Combined stock data saved at: {combined_file_path}\")\n"
      ],
      "metadata": {
        "id": "Z3FrM1QekVwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "246ad908-b38f-4df3-a34c-f56b6dcddcf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for John Deere (DE)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for John Deere (DE) saved successfully at /content/FinancialData/DE_stock_data.csv\n",
            "Downloading data for Archer-Daniels-Midland (ADM)...\n",
            "Data for Archer-Daniels-Midland (ADM) saved successfully at /content/FinancialData/ADM_stock_data.csv\n",
            "Downloading data for Bunge Ltd (BG)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for Bunge Ltd (BG) saved successfully at /content/FinancialData/BG_stock_data.csv\n",
            "Downloading data for The Mosaic Company (MOS)...\n",
            "Data for The Mosaic Company (MOS) saved successfully at /content/FinancialData/MOS_stock_data.csv\n",
            "Downloading data for Corteva (CTVA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for Corteva (CTVA) saved successfully at /content/FinancialData/CTVA_stock_data.csv\n",
            "Combined stock data saved at: /content/FinancialData/combined_stock_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that both TensorFlow (2.14.0) and TensorFlow Federated (0.87.0) are successfully installed and ready to use, we're all set to start working on your project. Let's begin our financial analysis using TensorFlow Federated Learning with the stock data, here's a simple structure to get started:\n",
        "Steps for Using TensorFlow Federated Learning:\n",
        "\n",
        "1. Prepare the Dataset: Organize our stock data for each company into client datasets for federated learning.\n",
        "2. Define the Model: Build a machine learning model (e.g., for stock price prediction or volatility analysis).\n",
        "3. Federated Training: Set up the federated learning process where each company acts as a client in the federated environment.\n",
        "4. Evaluate the Model: Assess the performance of the federated model across all clients.\n",
        "\n",
        "Here's an outline of how you can structure the code:"
      ],
      "metadata": {
        "id": "lYvC2k8Git6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path to the saved stock data in Colab\n",
        "base_dir = '/content/FinancialData'\n",
        "\n",
        "# Load each company's stock data from the saved CSV files\n",
        "def load_company_data(ticker):\n",
        "    file_path = os.path.join(base_dir, f\"{ticker}_stock_data.csv\")\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "# Define a function to load stock data for all companies and convert it to tf.data.Dataset\n",
        "def create_client_data():\n",
        "    companies = ['DE', 'ADM', 'BG', 'MOS', 'CTVA']  # List of ticker symbols\n",
        "    client_data = []\n",
        "\n",
        "    for ticker in companies:\n",
        "        data = load_company_data(ticker)\n",
        "        # Debug: Check if data is loaded correctly\n",
        "        #print(f\"Data for {ticker} loaded. Sample:\\n\", data.head())\n",
        "\n",
        "        # Use relevant features for the model (e.g., Close price, Volume)\n",
        "        features = data[['Close', 'Volume']].fillna(0).values.astype('float32')  # Changed to float32\n",
        "        labels = data[['Close']].fillna(0).values.astype('float32')  # Predicting Close price, changed to float32\n",
        "\n",
        "        # Debug: Check features and labels\n",
        "        #print(f\"Features shape for {ticker}: {features.shape}\")\n",
        "        #print(f\"Labels shape for {ticker}: {labels.shape}\")\n",
        "\n",
        "        # Create dataset and check batches\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "        dataset = dataset.batch(32)  # Batch the dataset\n",
        "        client_data.append(dataset)\n",
        "\n",
        "        # Debug: Check batched dataset\n",
        "        #print(f\"Batched dataset for {ticker}:\")\n",
        "        for batch in dataset:\n",
        "            #print(batch)\n",
        "            break  # Print only the first batch for debugging\n",
        "\n",
        "    return client_data\n",
        "\n",
        "# Create a simple model for stock price prediction (e.g., linear regression)\n",
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(10, activation='relu', input_shape=(2,)),  # 2 features: Close price, Volume\n",
        "        tf.keras.layers.Dense(1)  # Output layer for predicting next price\n",
        "    ])\n",
        "\n",
        "    # Debug: Check model summary\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "# Define a TFF model\n",
        "def model_fn():\n",
        "    try:\n",
        "        # Create the Keras model using the function defined earlier\n",
        "        keras_model = create_model()\n",
        "\n",
        "        # Ensure input_spec matches the dataset structure (features, labels)\n",
        "        input_spec = (\n",
        "            tf.TensorSpec(shape=[None, 2], dtype=tf.float32),  # Features (2: Close price, Volume)\n",
        "            tf.TensorSpec(shape=[None, 1], dtype=tf.float32)   # Labels (1: Close price prediction)\n",
        "        )\n",
        "\n",
        "        # Create a TFF model from the Keras model\n",
        "        tff_model = tff.learning.models.from_keras_model(\n",
        "            keras_model=keras_model,\n",
        "            input_spec=input_spec,\n",
        "            loss=tf.keras.losses.MeanSquaredError(),  # Loss function (regression task)\n",
        "            metrics=[tf.keras.metrics.MeanSquaredError()]  # Metrics to track\n",
        "        )\n",
        "\n",
        "        print(\"TFF model created successfully.\")\n",
        "\n",
        "        return tff_model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error while creating TFF model: {e}\")\n",
        "        raise e\n",
        "\n",
        "# Federated learning process setup\n",
        "def federated_training():\n",
        "    client_data = create_client_data()\n",
        "\n",
        "    # Use TFF's internal sgdm optimizer instead of Keras's optimizer\n",
        "    client_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=0.01)\n",
        "    server_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=1.0)\n",
        "\n",
        "    # Build federated averaging process using TFF's internal optimizers\n",
        "    iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn=model_fn,\n",
        "        client_optimizer_fn=client_optimizer_fn,  # Pass the optimizer directly\n",
        "        server_optimizer_fn=server_optimizer_fn   # Pass the optimizer directly\n",
        "    )\n",
        "\n",
        "    # Initialize the model state\n",
        "    state = iterative_process.initialize()\n",
        "\n",
        "    # Simulate training across clients (5 companies)\n",
        "    for round_num in range(1, 11):\n",
        "        state, metrics = iterative_process.next(state, client_data)\n",
        "        print(f'Round {round_num}, Metrics: {metrics}')\n",
        "\n",
        "# Start federated training\n",
        "federated_training()\n"
      ],
      "metadata": {
        "id": "NKxgPqGO-HUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kOmx0SkP6yky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ZqcHIFP6yLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z8YJfXUG6x-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path to the saved stock data in Colab\n",
        "base_dir = '/content/FinancialData'\n",
        "\n",
        "# Load each company's stock data from the saved CSV files\n",
        "def load_company_data(ticker):\n",
        "    file_path = os.path.join(base_dir, f\"{ticker}_stock_data.csv\")\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "# Define a function to load stock data for all companies and convert it to tf.data.Dataset\n",
        "def create_client_data():\n",
        "    companies = ['DE', 'ADM', 'BG', 'MOS', 'CTVA']  # List of ticker symbols\n",
        "    client_data = []\n",
        "\n",
        "    for ticker in companies:\n",
        "        data = load_company_data(ticker)\n",
        "        # Debug: Check if data is loaded correctly\n",
        "        #print(f\"Data for {ticker} loaded. Sample:\\n\", data.head())\n",
        "\n",
        "        # Use relevant features for the model (e.g., Close price, Volume)\n",
        "        features = data[['Close', 'Volume']].fillna(0).values.astype('float32')  # Changed to float32\n",
        "        labels = data[['Close']].fillna(0).values.astype('float32')  # Predicting Close price, changed to float32\n",
        "\n",
        "        # Debug: Check features and labels\n",
        "        #print(f\"Features shape for {ticker}: {features.shape}\")\n",
        "        #print(f\"Labels shape for {ticker}: {labels.shape}\")\n",
        "\n",
        "        # Create dataset and check batches\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "        dataset = dataset.batch(32)  # Batch the dataset\n",
        "        client_data.append(dataset)\n",
        "\n",
        "        # Debug: Check batched dataset\n",
        "        #print(f\"Batched dataset for {ticker}:\")\n",
        "        for batch in dataset:\n",
        "            #print(batch)\n",
        "            break  # Print only the first batch for debugging\n",
        "\n",
        "    return client_data\n",
        "\n",
        "# Create a simple model for stock price prediction (e.g., linear regression)\n",
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(10, activation='relu', input_shape=(2,)),  # 2 features: Close price, Volume\n",
        "        tf.keras.layers.Dense(1)  # Output layer for predicting next price\n",
        "    ])\n",
        "\n",
        "    # Debug: Check model summary\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "# Define a TFF model\n",
        "def model_fn():\n",
        "    try:\n",
        "        # Create the Keras model using the function defined earlier\n",
        "        keras_model = create_model()\n",
        "\n",
        "        # Ensure input_spec matches the dataset structure (features, labels)\n",
        "        input_spec = (\n",
        "            tf.TensorSpec(shape=[None, 2], dtype=tf.float32),  # Features (2: Close price, Volume)\n",
        "            tf.TensorSpec(shape=[None, 1], dtype=tf.float32)   # Labels (1: Close price prediction)\n",
        "        )\n",
        "\n",
        "        # Create a TFF model from the Keras model\n",
        "        tff_model = tff.learning.models.from_keras_model(\n",
        "            keras_model=keras_model,\n",
        "            input_spec=input_spec,\n",
        "            loss=tf.keras.losses.MeanSquaredError(),  # Loss function (regression task)\n",
        "            metrics=[tf.keras.metrics.MeanSquaredError()]  # Metrics to track\n",
        "        )\n",
        "\n",
        "        print(\"TFF model created successfully.\")\n",
        "\n",
        "        return tff_model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error while creating TFF model: {e}\")\n",
        "        raise e\n",
        "\n",
        "# Federated learning process setup\n",
        "def federated_training():\n",
        "    client_data = create_client_data()\n",
        "\n",
        "    # Use TFF's internal sgdm optimizer instead of Keras's optimizer\n",
        "    client_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=0.01)\n",
        "    server_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=1.0)\n",
        "\n",
        "    # Build federated averaging process using TFF's internal optimizers\n",
        "    iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn=model_fn,\n",
        "        client_optimizer_fn=client_optimizer_fn,  # Pass the optimizer directly\n",
        "        server_optimizer_fn=server_optimizer_fn   # Pass the optimizer directly\n",
        "    )\n",
        "\n",
        "    # Initialize the model state\n",
        "    state = iterative_process.initialize()\n",
        "\n",
        "    # Simulate training across clients (5 companies)\n",
        "    for round_num in range(1, 11):\n",
        "        state, metrics = iterative_process.next(state, client_data)\n",
        "        print(f'Round {round_num}, Metrics: {metrics}')\n",
        "\n",
        "# Start federated training\n",
        "federated_training()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4qJ4rBo62GM",
        "outputId": "8d90342f-2606-4a6b-b0f0-9c06d5ceac32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                30        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41 (164.00 Byte)\n",
            "Trainable params: 41 (164.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "TFF model created successfully.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                30        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41 (164.00 Byte)\n",
            "Trainable params: 41 (164.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "TFF model created successfully.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                30        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41 (164.00 Byte)\n",
            "Trainable params: 41 (164.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "TFF model created successfully.\n",
            "Round 1, Metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_squared_error', 78207885000.0), ('loss', 78207885000.0), ('num_examples', 6285), ('num_batches', 200)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 2, Metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_squared_error', 96265000.0), ('loss', 96265000.0), ('num_examples', 6285), ('num_batches', 200)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 3, Metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_squared_error', 19102316.0), ('loss', 19102316.0), ('num_examples', 6285), ('num_batches', 200)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 4, Metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_squared_error', 3788853.0), ('loss', 3788853.0), ('num_examples', 6285), ('num_batches', 200)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 5, Metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_squared_error', 753456.5), ('loss', 753456.5), ('num_examples', 6285), ('num_batches', 200)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 6, Metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_squared_error', 153422.25), ('loss', 153422.25), ('num_examples', 6285), ('num_batches', 200)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 7, Metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_squared_error', 35538.15), ('loss', 35538.15), ('num_examples', 6285), ('num_batches', 200)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 8, Metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_squared_error', 12705.355), ('loss', 12705.355), ('num_examples', 6285), ('num_batches', 200)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 9, Metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_squared_error', 8430.274), ('loss', 8430.274), ('num_examples', 6285), ('num_batches', 200)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 10, Metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('mean_squared_error', 7697.195), ('loss', 7697.195), ('num_examples', 6285), ('num_batches', 200)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xRtQMfxH84RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9aOmQhqo83l1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}